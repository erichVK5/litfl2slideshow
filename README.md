# litfl2slideshow
convert images from a batch downloaded website into a labelled slideshow for standalone use

Given a web site with a library of images embedded in HTML for teaching purposes, you might prefer to dispense with the browser and create a local directory of the same images with labels, to allow a simple slideshow.

This repository contains a set of bash shell scripts that employ the sed and grep utilities and awk to pre-process the cloned website data, which then allows a simple java utility to embed the downloaded image into a larger image that includes three text labels below the image. The labels consist of 1) the poath to the file, 2) the file name, and 3) the 'alt' text label from the HTML which embeds the image. The scripts attempt to exclude content that is not related to the teaching content.

From a purely hypothetical standpoint, you might have an emergency medicine website with many GB of data available via wget, within which there are only a few hundred MB of actual images. The rest is endlessly repetitive wrappers and boilerplate HTML code, mixed in with a bit of javascript. The text information that contains the labels for the images would come to only a few MB, hypothetically.

Hypothetically, how would one make such a slide show for personal, non-commercial use?

The first step is to do a batch download of the website with wget. Obviously, try not to do this routinely, or at all, as it will clobber the website hosting provider. Also, ensure that your plans are compatible with the website's terms of use.

Having created a local copy of the website, the next step is to create a list of files ending in .html that can then be mined for image (<img... />) tags.

At this point, irrelevant directories and content could be pruned or moved out of the local clone of the website. To then create a listing of html files within the local clone, for the sake of example with a hypothetical website, as follows:

./html_extraction.sh liftl.com/ > litfl_html.txt

Having now extracted a file listing containing just the HTML files, we then proceed to extract the relevant HTML <img> tags from these files as follows:

./extract_ECG_img_tags.sh liftl_html.txt > ECG_image_tags.txt

the next step is to turn each image tag line into a ' ' delimited list that looks like

relative_path/to/images/an/image.jpg "ECG description"

which can be used at the root level of the locally cloned website, to facilitate final processing, and do this as follows:

./trim_ECG_imagetags.sh ECG_image_tags.txt > distilled_ECG_data.txt

at this point we are one step away from creating larger images which embed the original image, and a text label below it. First, we create a local directory in the root level of the locally cloned website to put the labelled images into

cd liftl.org

cp ../distilled_ECG_data.txt .

mkdir modified

you then compile the java image labelling utility as follows:

javac labelImages.java

you then run the java labelling utility with the ' ' delimited data generated by trim_imagetags.sh as follows:

java labelImages distilled_ECG_data.txt

Wait a while, and you should then have thousands of images in the modified directory that are ideally suited to an educational slide show that can run standalone with no network access.

On linux, the image viewing utility 'eye of mate' has a random slideshow option, and can be installed with the following ubuntu incantation

sudo apt-get install eom

